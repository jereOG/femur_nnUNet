{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting\n",
    "\n",
    "This notebook implements the prediction of new labels and their evaluation. While the default nnUNet procedure involves an automatic search for the best configuration and model followed by ensemble prediction, here a single model was manually selected after evaluating different configurations on a single fold in order to reduce training and inference time. This model was then trained on the entire training dataset and used to predict the test images.\n",
    "For more details see `nnUNet/documentation/how_to_use_nnunet.md`.\n",
    "\n",
    "1. Prediction with the selected model\n",
    "2. Postprocessing\n",
    "3. Evaluating the performance of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "# Default paths for the datasets\n",
    "os.environ[\"nnUNet_raw\"] = str(current_dir / \"nnUNet_raw\")\n",
    "os.environ[\"nnUNet_preprocessed\"] = str(current_dir / \"nnUNet_preprocessed\")\n",
    "os.environ[\"nnUNet_results\"] = str(current_dir / \"nnUNet_results\")\n",
    "\n",
    "data_name = \"Dataset101_FemurCorrected\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If desired, the code below installs the pretrained 2D and 3D models that were found to perform best in the project for femur CT segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nnUNetv2_install_pretrained_model_from_zip 3D\n",
    "!nnUNetv2_install_pretrained_model_from_zip 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prediction with the selected model\n",
    "\n",
    "Predict all labels for the test images located in `nnUNet_raw/{data_name}/imagesTs` and store these in `predictions/not_postprocessed`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = f\"nnUNetv2_predict -i nnUNet_raw/{data_name}/imagesTs -o predictions/not_postprocessed -d 101 -f all -c 3d_fullres\"\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Postprocessing\n",
    "\n",
    "In order to apply postprocessing, first the command `nnUNetv2_find_best_configuration` has to be run to generate the corresponding postprocessing file. For this to work, the selected model has to be trained on all five folds of the training data beforehand.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nnUNetv2_find_best_configuration 101 -c 3d_fullres --disable_ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The postprcoessing file can now be found at `nnUNet_results/{data_name}/nnUNetTrainer__nnUNetPlans__3d_fullres/crossval_results_folds_0_1_2_3_4/postprocessing.pkl`. The results are stored in `predictions/not_postprocessed`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_file_path = Path(f\"nnUNet_results/{data_name}/nnUNetTrainer__nnUNetPlans__3d_fullres/crossval_results_folds_0_1_2_3_4/postprocessing.pkl\").resolve()\n",
    "\n",
    "!nnUNetv2_apply_postprocessing -i predictions/not_postprocessed -o predictions/postprocessed -pp_pkl_file {processing_file_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "import panel as pn\n",
    "import holoviews as hv\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import skimage.measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Evaluation starts by calculating the quantitave petformance measure: Dice score, specificity, sensitivity and average surface distance. \n",
    "First, select the desired predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directories containing predictions from different models\n",
    "prediction_dirs = [\n",
    "    'predictions/postprocessed'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nrrd(file_path):\n",
    "    image = sitk.ReadImage(file_path)\n",
    "    array = sitk.GetArrayFromImage(image)\n",
    "    return array\n",
    "\n",
    "def calculate_dice_coefficient(pred, truth, epsilon=1e-5):\n",
    "    intersection = np.sum((pred == truth) & (pred != 0))\n",
    "    volume_sum = np.sum(pred != 0) + np.sum(truth != 0)\n",
    "    dice = (2. * intersection + epsilon) / (volume_sum + epsilon)\n",
    "    return dice\n",
    "\n",
    "def calculate_sensitivity(pred, truth):\n",
    "    true_positive = np.sum((pred == 1) & (truth == 1))\n",
    "    false_negative = np.sum((pred == 0) & (truth == 1))\n",
    "    sensitivity = true_positive / (true_positive + false_negative + 1e-5)\n",
    "    return sensitivity\n",
    "\n",
    "def calculate_specificity(pred, truth):\n",
    "    true_negative = np.sum((pred == 0) & (truth == 0))\n",
    "    false_positive = np.sum((pred == 1) & (truth == 0))\n",
    "    specificity = true_negative / (true_negative + false_positive + 1e-5)\n",
    "    return specificity\n",
    "\n",
    "# Average Surface Distance\n",
    "def calculate_asd(pred, truth):\n",
    "    pred_image = sitk.GetImageFromArray(pred)\n",
    "    truth_image = sitk.GetImageFromArray(truth)\n",
    "\n",
    "    pred_surface = sitk.LabelContour(pred_image)\n",
    "    truth_surface = sitk.LabelContour(truth_image)\n",
    "\n",
    "    pred_distance_map = sitk.SignedMaurerDistanceMap(pred_surface, squaredDistance=False, useImageSpacing=True)\n",
    "    truth_distance_map = sitk.SignedMaurerDistanceMap(truth_surface, squaredDistance=False, useImageSpacing=True)\n",
    "\n",
    "    # Convert to arrays\n",
    "    pred_distance_map_array = sitk.GetArrayFromImage(pred_distance_map)\n",
    "    truth_distance_map_array = sitk.GetArrayFromImage(truth_distance_map)\n",
    "\n",
    "    # Contours\n",
    "    pred2truth = pred_distance_map_array[truth != 0]\n",
    "    truth2pred = truth_distance_map_array[pred != 0]\n",
    "\n",
    "    asd = (np.mean(np.abs(pred2truth)) + np.mean(np.abs(truth2pred))) / 2.0\n",
    "    return asd\n",
    "\n",
    "def compare_labels(prediction_dirs, ground_truth_dir):\n",
    "    all_results = []\n",
    "\n",
    "    for model_idx, predicted_dir in enumerate(prediction_dirs):\n",
    "        pred_files = sorted(os.listdir(predicted_dir))\n",
    "        truth_files = sorted(os.listdir(ground_truth_dir))\n",
    "\n",
    "        for pred_file, truth_file in zip(pred_files, truth_files):\n",
    "            pred_path = os.path.join(predicted_dir, pred_file)\n",
    "            truth_path = os.path.join(ground_truth_dir, truth_file)\n",
    "            \n",
    "            pred_array = load_nrrd(pred_path)\n",
    "            truth_array = load_nrrd(truth_path)\n",
    "            \n",
    "            dice_score = calculate_dice_coefficient(pred_array, truth_array)\n",
    "            sensitivity = calculate_sensitivity(pred_array, truth_array)\n",
    "            specificity = calculate_specificity(pred_array, truth_array)\n",
    "            asd = calculate_asd(pred_array, truth_array)\n",
    "            \n",
    "            all_results.append({\n",
    "                'model': f'Model_{model_idx + 1}',\n",
    "                'file': pred_file,\n",
    "                'DICE': dice_score,\n",
    "                'Sensitivity': sensitivity,\n",
    "                'Specificity': specificity,\n",
    "                'ASD': asd,\n",
    "                'pred_array': pred_array, \n",
    "                'truth_array': truth_array\n",
    "            })\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "ground_truth_labels_dir = f\"nnUNet_raw/{data_name}/labelsTs\"\n",
    "\n",
    "results = compare_labels(prediction_dirs, ground_truth_labels_dir)\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "average_metrics = df.groupby(\"model\")[[\"DICE\", \"Sensitivity\", \"Specificity\", \"ASD\"]].mean()\n",
    "print(average_metrics)\n",
    "average_metrics.to_csv(\"average_metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, an interactive plot is generated, allowing one to switch between different models as well as different performance metrics. The plot displays the distribution of each metric across the images as a histogram.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.extension()\n",
    "\n",
    "# Switch between models and metrics\n",
    "model_selector = pn.widgets.Select(name='Model', options=df['model'].unique().tolist())\n",
    "metric_selector = pn.widgets.Select(name='Metric', options=['DICE', 'Sensitivity', 'Specificity', 'ASD'])\n",
    "\n",
    "@pn.depends(model_selector, metric_selector)\n",
    "def plot_histogram(model, metric):\n",
    "    filtered_df = df[df['model'] == model]\n",
    "    histogram = filtered_df.hvplot.hist(y=metric, bins=15, alpha=0.7, height=400, width=600, title=f'{metric.capitalize()} Distribution for {model}')\n",
    "    return histogram\n",
    "\n",
    "histogram_layout = pn.Column(\n",
    "    pn.Row(model_selector, metric_selector),\n",
    "    plot_histogram\n",
    ")\n",
    "\n",
    "histogram_layout.servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here an interactive boxplot is generated, displaying the distribution of each metric across the images, side by side for the different models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.extension()\n",
    "\n",
    "# Switch between metrics\n",
    "metric_selector = pn.widgets.Select(name='Metric', options=['DICE', 'Sensitivity', 'Specificity', 'ASD'])\n",
    "\n",
    "@pn.depends(metric_selector)\n",
    "def plot_boxplot(metric):\n",
    "    boxplot = df.hvplot.box(y=metric, by='model', height=400, width=600, title=f'{metric.capitalize()} Boxplot Across Models')\n",
    "    return boxplot\n",
    "boxplot_layout = pn.Column(\n",
    "    metric_selector,\n",
    "    plot_boxplot\n",
    ")\n",
    "boxplot_layout.servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code generates a visualization plot for a specified image and model, featuring a slider to select the appropriate slice of the image. The plot highlights the errors in the predicted labels compared to the ground truth labels. Dark violet pixels represent areas where the model incorrectly predicted bone, while light violet pixels indicate regions where the model falsely predicted the background.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First select here the desired model and image\n",
    "model = \"Model_1\"\n",
    "image_name = \"19L_fall.nrrd\"\n",
    "\n",
    "df_filtered = df[(df['model'] == model) & (df['file'] == image_name)]\n",
    "\n",
    "truth_array = df_filtered.iloc[0]['truth_array']\n",
    "pred_array = df_filtered.iloc[0]['pred_array']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_error_overlay_images(pred_array, truth_array, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for slice_idx in range(pred_array.shape[0]):\n",
    "        error_map = np.zeros_like(pred_array[slice_idx], dtype=np.uint8)\n",
    "        error_map[(pred_array[slice_idx] != truth_array[slice_idx]) & (truth_array[slice_idx] == 1)] = 1\n",
    "        error_map[(pred_array[slice_idx] != truth_array[slice_idx]) & (truth_array[slice_idx] == 0)] = 2\n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(truth_array[slice_idx], cmap='gray', alpha=0.5)\n",
    "        plt.imshow(error_map, cmap='cool', alpha=0.5)\n",
    "        plt.title(f'Error Overlay on Slice {slice_idx}')\n",
    "        plt.axis('off')\n",
    "        plt.savefig(os.path.join(output_dir, f\"slice_{slice_idx}.png\"), bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "\n",
    "output_dir = \"evaluation/images/error_overlays\"\n",
    "save_error_overlay_images(pred_array, truth_array, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_slice_index(filename):\n",
    "    match = re.search(r'slice_(\\d+).png', filename)\n",
    "    return int(match.group(1)) if match else -1\n",
    "\n",
    "image_files = sorted([f\"error_overlays/{file}\" for file in os.listdir(output_dir) if file.endswith('.png')],\n",
    "                     key=lambda x: extract_slice_index(x))\n",
    "\n",
    "def view_image(slice_idx):\n",
    "    return pn.pane.PNG(image_files[slice_idx], width=400, height=400)\n",
    "\n",
    "# Select slides\n",
    "slice_slider = pn.widgets.IntSlider(name='Slice Index', start=0, end=len(image_files) - 1, step=1, value=0)\n",
    "interactive_view = pn.bind(view_image, slice_idx=slice_slider)\n",
    "layout = pn.Column(slice_slider, interactive_view)\n",
    "layout.servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the error visualization, the following contour visualization provides a clearer representation of the models accuracy as most errors are likely concentrated on the outer edges of the bone components. The green contours represent the ground truth labels, while the red contours indicate the predicted labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_contour_images(pred_array, truth_array, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for slice_idx in range(pred_array.shape[0]):\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(truth_array[slice_idx], cmap='gray', alpha=0.5)\n",
    "\n",
    "        pred_contour = skimage.measure.find_contours(pred_array[slice_idx], level=0.5)\n",
    "        truth_contour = skimage.measure.find_contours(truth_array[slice_idx], level=0.5)\n",
    "\n",
    "        for contour in pred_contour:\n",
    "            plt.plot(contour[:, 1], contour[:, 0], 'r', linewidth=2)\n",
    "        for contour in truth_contour:\n",
    "            plt.plot(contour[:, 1], contour[:, 0], 'g', linewidth=2)\n",
    "\n",
    "        plt.title(f'Contours on Slice {slice_idx}')\n",
    "        plt.axis('off')\n",
    "        plt.savefig(os.path.join(output_dir, f\"slice_{slice_idx}.png\"), bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "\n",
    "output_dir = \"evaluation/images/contour_overlays\"\n",
    "save_contour_images(pred_array, truth_array, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_slice_index(filename):\n",
    "    match = re.search(r'slice_(\\d+).png', filename)\n",
    "    return int(match.group(1)) if match else -1\n",
    "\n",
    "image_files = sorted([f\"contour_overlays/{file}\" for file in os.listdir(output_dir) if file.endswith('.png')],\n",
    "                     key=lambda x: extract_slice_index(x))\n",
    "\n",
    "def view_image(slice_idx):\n",
    "    return pn.pane.PNG(image_files[slice_idx], width=400, height=400)\n",
    "\n",
    "slice_slider = pn.widgets.IntSlider(name='Slice Index', start=0, end=len(image_files) - 1, step=1, value=0)\n",
    "\n",
    "interactive_view = pn.bind(view_image, slice_idx=slice_slider)\n",
    "layout = pn.Column(slice_slider, interactive_view)\n",
    "layout.servable()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bones",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
