{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "This notebook implements the following data preprocessing steps:\n",
    "1. Sample the test set\n",
    "2. Rename the `.nrrd` files to follow the nnUnet naming conventions\n",
    "3. Generate the nnUnet datasets in the correct format\n",
    "\n",
    "This preprocessing only works for the format of the data that was used in the paper. For more information on how to generally format data correctly look into `nnUNet/documentation/dataset_format.md`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the preprocessing, place the images and labels in the `data` directory in the `data/images` and `data/labels` subdirectories correspondingly. The images have to be in `.nrrd` format. The following code block will then create a training-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sample the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Percentage of samples used in the training split\n",
    "split_ratio = 0.87\n",
    "\n",
    "# Source directories for images, labels, and corrected labels\n",
    "source_dir_images = Path('data/images')\n",
    "source_dir_labels = Path('data/labels')\n",
    "\n",
    "# Destination directories for train and test splits\n",
    "train_dir_images = Path('data/train/images')\n",
    "test_dir_images = Path('data/test/images')\n",
    "train_dir_labels = Path('data/train/labels')\n",
    "test_dir_labels = Path('data/test/labels')\n",
    "\n",
    "def clear_directory(directory):\n",
    "    if directory.exists():\n",
    "        shutil.rmtree(directory)\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Clear before copying new files\n",
    "clear_directory(train_dir_images)\n",
    "clear_directory(test_dir_images)\n",
    "clear_directory(train_dir_labels)\n",
    "clear_directory(test_dir_labels)\n",
    "\n",
    "\n",
    "random.seed(123)\n",
    "\n",
    "files_images = [file for file in source_dir_images.iterdir() if file.is_file()]\n",
    "\n",
    "random.shuffle(files_images)\n",
    "\n",
    "split_index = int(len(files_images) * split_ratio)\n",
    "\n",
    "train_files = files_images[:split_index]\n",
    "test_files = files_images[split_index:]\n",
    "\n",
    "# Copy files to the appropriate directory\n",
    "def copy_files(files, destination_images, destination_labels):\n",
    "    for file in files:\n",
    "        # Copy image file\n",
    "        shutil.copy(file, destination_images / file.name)\n",
    "\n",
    "        # Copy corresponding label file if it exists\n",
    "        label_path = source_dir_labels / file.name\n",
    "        if label_path.exists():\n",
    "            shutil.copy(label_path, destination_labels / file.name)\n",
    "        else:\n",
    "            print(f\"Label not found for {file.name}\")\n",
    "\n",
    "\n",
    "\n",
    "# Copy training files\n",
    "copy_files(train_files, train_dir_images, train_dir_labels)\n",
    "\n",
    "# Copy testing files\n",
    "copy_files(test_files, test_dir_images, test_dir_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Rename the `.nrrd` files to follow the nnUnet naming conventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_files(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".nrrd\"):\n",
    "            # Check if there is more than one underscore\n",
    "            if filename.count('_') > 1:\n",
    "                new_filename = filename.replace('_', '', 1)\n",
    "                os.rename(os.path.join(directory, filename), os.path.join(directory, new_filename))\n",
    "                print(f\"Renamed: {filename} to {new_filename}\")\n",
    "            else:\n",
    "                print(f\"No rename needed: {filename}\")\n",
    "\n",
    "rename_files(\"data/test/labels\")\n",
    "rename_files(\"data/train/labels\")\n",
    "rename_files(\"data/test/images\")\n",
    "rename_files(\"data/train/images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate the nnUnet datasets in the correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the datasetname and ID\n",
    "data_name = \"Dataset101_FemurCorrected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dirs = {\n",
    "    \"test_labels\": Path(\"data/test/labels\"),\n",
    "    \"training_labels\": Path(\"data/train/labels\"),\n",
    "    \"test_images\": Path(\"data/test/images\"),\n",
    "    \"train_images\": Path(\"data/train/images\")\n",
    "}\n",
    "\n",
    "destination_dirs = {\n",
    "    \"test_labels\": Path(f\"nnUNet_raw/{data_name}/labelsTs\"),\n",
    "    \"training_labels\": Path(f\"nnUNet_raw/{data_name}/labelsTr\"),\n",
    "    \"test_images\": Path(f\"nnUNet_raw/{data_name}/imagesTs\"),\n",
    "    \"train_images\": Path(f\"nnUNet_raw/{data_name}/imagesTr\")\n",
    "}\n",
    "\n",
    "def clear_and_create_directory(directory):\n",
    "    if directory.exists():\n",
    "        shutil.rmtree(directory)\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def copy_and_rename_files(source_dir, destination_dir, append_str=\"_0000\"):\n",
    "    for file in source_dir.iterdir():\n",
    "        if file.is_file():\n",
    "            new_filename = file.name\n",
    "            if \"image\" in source_dir.name.lower() and file.suffix in ['.nrrd', '.nii', '.nii.gz']:\n",
    "                new_filename = file.stem + append_str + file.suffix\n",
    "            shutil.copy(file, destination_dir / new_filename)\n",
    "\n",
    "for key in source_dirs:\n",
    "    clear_and_create_directory(destination_dirs[key])\n",
    "    copy_and_rename_files(source_dirs[key], destination_dirs[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary folders for later training\n",
    "dir1 = Path(\"nnUNet_preprocessed\")\n",
    "dir2 = Path(\"nnUNet_results\")\n",
    "\n",
    "if dir1.exists():\n",
    "    print(f\"Warning: The directory '{dir1}' already exists.\")\n",
    "    sys.exit(1)\n",
    "else:\n",
    "    dir1.mkdir(parents=True, exist_ok=False)\n",
    "    print(f\"Directory '{dir1}' created successfully.\")\n",
    "\n",
    "if dir2.exists():\n",
    "    print(f\"Warning: The directory '{dir2}' already exists.\")\n",
    "    sys.exit(1)\n",
    "else:\n",
    "    dir2.mkdir(parents=True, exist_ok=False)\n",
    "    print(f\"Directory '{dir2}' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next a `dataset.json` file with details about the dataset has to be created and put into `nnUNet_raw/Dataset101_FemurCorrected`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesTr_dir = Path(f\"nnUNet_raw/{data_name}/imagesTr\")\n",
    "num_training_files = len(list(imagesTr_dir.glob('*')))\n",
    "\n",
    "data = {\n",
    "    \"channel_names\": { \n",
    "        \"0\": \"CT\"\n",
    "    },\n",
    "    \"labels\": { \n",
    "        \"background\": 0,\n",
    "        \"bone\": 1\n",
    "    },\n",
    "    \"numTraining\": num_training_files,\n",
    "    \"file_ending\": \".nrrd\"\n",
    "}\n",
    "\n",
    "save_directory = Path(f\"nnUNet_raw/{data_name}\")  \n",
    "json_filename = save_directory / \"dataset.json\"\n",
    "\n",
    "with open(json_filename, 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=2)\n",
    "\n",
    "print(f\"JSON file '{json_filename}' created successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bones",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
