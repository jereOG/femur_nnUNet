{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f943318c",
   "metadata": {},
   "source": [
    "# Training\n",
    "This notebook demonstrates how to train a  model using the nnUNet framework. For more detailed instructions see `nnUNet/documentation/how_to_use_nnunet.md`.\n",
    "\n",
    "## Sections:\n",
    "1. Environment Setup\n",
    "2. Hyperparameter Configuration\n",
    "3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d15404",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, we set up the necessary environment variables that nnUNet uses to locate datasets and store results. If the nnUnet datasets were generated with the \"preprocessing.ipynb\" notebook, the default paths should work correctly automatically. Otherwise ensure these paths are correctly set according to your directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T10:38:31.795510Z",
     "start_time": "2024-08-07T10:38:31.792578Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "# Default paths for the datasets\n",
    "os.environ[\"nnUNet_raw\"] = str(current_dir / \"nnUNet_raw\")\n",
    "os.environ[\"nnUNet_preprocessed\"] = str(current_dir / \"nnUNet_preprocessed\")\n",
    "os.environ[\"nnUNet_results\"] = str(current_dir / \"nnUNet_results\")\n",
    "\n",
    "data_name = \"Dataset101_FemurCorrected\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d3d42e",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "The data preprocessing step ensures that the datasets are in the correct format and verifies their integrity. If using only one dataset with the default setup, this dataset will have the ID 101."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6138eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Dataset 101 and verify its integrity\n",
    "!nnUNetv2_plan_and_preprocess -d 101 --verify_dataset_integrity\n",
    "\n",
    "# A different planner is needed for the usage of residual nets\n",
    "# Here the medium residual network was chosen as it is the largest that still fits into 16GB VRAM\n",
    "!nnUNetv2_plan_experiment -d 101 -pl nnUNetPlannerResEncM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcfd0d5",
   "metadata": {},
   "source": [
    "## 2. Hyperparameter Configuration\n",
    "\n",
    "Many parameters can be modified by utilizing the plans json files, see `nnUNet/documentation/explanation_plans_files.md` for more details. All different settings that were tried out in the report can be selected in the next code cell. The actual modified plans files are `nnUNet_preprocessed/{data_name}/nnUNetPlans.json` and `nnUNet_preprocessed/{data_name}/nnUNetResEncUNetMPlans.json`.\n",
    "Parameters that are not covered in the plans files have to be set directly in the python files. For example, the number of training epochs in this report was changed from the default 1000 epochs to 100 epochs by changing the variable `num_epochs` in the file `nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py`. This was only set during the parameter optimization in order to be able to try out a complete grid-search of all possible combinations of parameter values found in the code cell below.\n",
    "The different data augmentation is chosen by selecting a different trainer file, for example the trainer for DA5 augmentation is found at `nnUNet/nnunetv2/training/nnUNetTrainer/variants/nnUNetTrainerDA5.py`.The mean validation Dice score for each configuration can be found at the end of their respecitve `training_log.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f474f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the plans files for the different configurations to work\n",
    "\n",
    "file_path_1 = f\"nnUNet_preprocessed/{data_name}/nnUNetPlans.json\"\n",
    "file_path_2 = f\"nnUNet_preprocessed/{data_name}/nnUNetResEncUNetMPlans.json\"\n",
    "\n",
    "additional_config_1 = {\n",
    "    \"3d_fullresBS4\": {\n",
    "        \"inherits_from\": \"3d_fullres\",\n",
    "        \"batch_size\": 4\n",
    "    },\n",
    "    \"2dBS4\": {\n",
    "        \"inherits_from\": \"2d\",\n",
    "        \"batch_size\": 744\n",
    "    },\n",
    "    \"3d_fullresBS6\": {\n",
    "        \"inherits_from\": \"3d_fullres\",\n",
    "        \"batch_size\": 6\n",
    "    },\n",
    "    \"2dBS6\": {\n",
    "        \"inherits_from\": \"2d\",\n",
    "        \"batch_size\": 1116\n",
    "    }\n",
    "}\n",
    "\n",
    "additional_config_2 = {\n",
    "    \"3d_fullresBS3\": {\n",
    "        \"inherits_from\": \"3d_fullres\",\n",
    "        \"batch_size\": 3\n",
    "    },\n",
    "    \"2dBS3\": {\n",
    "        \"inherits_from\": \"2d\",\n",
    "        \"batch_size\": 558\n",
    "    },\n",
    "    \"3d_fullresBS4\": {\n",
    "        \"inherits_from\": \"3d_fullres\",\n",
    "        \"batch_size\": 4\n",
    "    },\n",
    "    \"3d_fullresBS6\": {\n",
    "        \"inherits_from\": \"3d_fullres\",\n",
    "        \"batch_size\": 6\n",
    "    },\n",
    "    \"2dBS4\": {\n",
    "        \"inherits_from\": \"2d\",\n",
    "        \"batch_size\": 744\n",
    "    }\n",
    "}\n",
    "\n",
    "def update_json_file(file_path, new_content):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        if not all(key in data['configurations'] for key in new_content.keys()):\n",
    "            data['configurations'].update(new_content)\n",
    "            \n",
    "            with open(file_path, 'w') as file:\n",
    "                json.dump(data, file, indent=4)\n",
    "            print(f\"Updated {file_path} with new configurations.\")\n",
    "        else:\n",
    "            print(\"The configurations are already present in the file.\")\n",
    "    else:\n",
    "        print(f\"The file {file_path} does not exist.\")\n",
    "\n",
    "update_json_file(file_path_1, additional_config_1)\n",
    "update_json_file(file_path_2, additional_config_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f65d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensional structures\n",
    "dim_structs = [\"2D\", \"3D\"]\n",
    "chosen_dim_struct = dim_structs[1]\n",
    "\n",
    "# Batch sizes, actual values are different depending on the dimensional as well as the network structure:\n",
    "#   default network:\n",
    "#       2D ... small = 372, medium = 744, large = 1116\n",
    "#       3D ... small = 2, medium = 4, large = 6 \n",
    "#   residual encoder network:\n",
    "#       2D ... small = 377, medium = 558, large = 744\n",
    "#       3D ... small = medium = 3, large = 4\n",
    "batch_sizes = [\"small\", \"medium\", \"large\"]\n",
    "chosen_batch_size = batch_sizes[2]\n",
    "\n",
    "# Data augmentation methods\n",
    "aug_methods = [\"default\", \"DA5\"]\n",
    "chosen_aug_method = aug_methods[0]\n",
    "    \n",
    "# Encoder structure\n",
    "network_structures = [\"default\", \"ResEnc\"]\n",
    "chosen_network_structure = network_structures[0]\n",
    "\n",
    "# choose the fold in a 5-fold cross validation-split (\"all\" trains the model on the whole training data)\n",
    "folds = [0, 1, 2, 3, 4, \"all\"]\n",
    "chosen_fold = folds[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0770ecd0",
   "metadata": {},
   "source": [
    "## 3. Model Training\n",
    "\n",
    "After chosing the desired parameters, run the next cell to start the training process and measure the needed time.\n",
    "Training logs can be found under `nnUNet_results/{data_name}/{model_name}` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4adb21e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnUNetv2_train 101 3d_fullresBS6 2\n",
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jere/.conda/envs/bones/bin/nnUNetv2_train\", line 8, in <module>\n",
      "    sys.exit(run_training_entry())\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jere/bones/nnUNet/nnunetv2/run/run_training.py\", line 275, in run_training_entry\n",
      "    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n",
      "  File \"/home/jere/bones/nnUNet/nnunetv2/run/run_training.py\", line 196, in run_training\n",
      "    nnunet_trainer = get_trainer_from_args(dataset_name_or_id, configuration, fold, trainer_class_name,\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jere/bones/nnUNet/nnunetv2/run/run_training.py\", line 64, in get_trainer_from_args\n",
      "    plans = load_json(plans_file)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jere/.conda/envs/bones/lib/python3.11/site-packages/batchgenerators/utilities/file_and_folder_operations.py\", line 68, in load_json\n",
      "    with open(file, 'r') as f:\n",
      "         ^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/jere/Documents/bones_public/nnUNet_preprocessed/Dataset101_FemurCorrected/nnUNetPlans.json'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.415040969848633"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if(chosen_aug_method==\"default\"):\n",
    "    trainer= \"\"\n",
    "if(chosen_aug_method==\"DA5\"):  \n",
    "    trainer = \" -tr nnUNetTrainerDA5\"\n",
    "\n",
    "if(chosen_dim_struct==\"2D\"):\n",
    "    if(chosen_batch_size==\"small\"):\n",
    "        if(chosen_network_structure==\"default\"):\n",
    "            command = f\"nnUNetv2_train 101 2d {chosen_fold}{trainer}\"\n",
    "        if(chosen_network_structure==\"ResEnc\"):\n",
    "            command = f\"nnUNetv2_train 101 2d {chosen_fold}{trainer} -p nnUNetResEncUNetMPlans\"\n",
    "    if(chosen_batch_size==\"medium\"):\n",
    "        if(chosen_network_structure==\"default\"):\n",
    "            command = f\"nnUNetv2_train 101 2dBS4 {chosen_fold}{trainer}\"\n",
    "        if(chosen_network_structure==\"ResEnc\"):\n",
    "            command = f\"nnUNetv2_train 101 2dBS3 {chosen_fold}{trainer} -p nnUNetResEncUNetMPlans\"\n",
    "    if(chosen_batch_size==\"large\"):\n",
    "        if(chosen_network_structure==\"default\"):\n",
    "            command = f\"nnUNetv2_train 101 2dBS6 {chosen_fold}{trainer}\"\n",
    "        if(chosen_network_structure==\"ResEnc\"):\n",
    "            command = f\"nnUNetv2_train 101 2dBS4 {chosen_fold}{trainer} -p nnUNetResEncUNetMPlans\"\n",
    "if(chosen_dim_struct==\"3D\"):\n",
    "    if(chosen_batch_size==\"small\"):\n",
    "        if(chosen_network_structure==\"default\"):\n",
    "            command = f\"nnUNetv2_train 101 3d_fullres {chosen_fold}{trainer}\"\n",
    "        if(chosen_network_structure==\"ResEnc\"):\n",
    "            command = f\"nnUNetv2_train 101 3d_fullres {chosen_fold}{trainer} -p nnUNetResEncUNetMPlans\"\n",
    "    if(chosen_batch_size==\"medium\"):\n",
    "        if(chosen_network_structure==\"default\"):\n",
    "            command = f\"nnUNetv2_train 101 3d_fullresBS4 {chosen_fold}{trainer}\"\n",
    "        if(chosen_network_structure==\"ResEnc\"):\n",
    "            command = f\"nnUNetv2_train 101 3d_fullresBS3 {chosen_fold}{trainer} -p nnUNetResEncUNetMPlans\"\n",
    "    if(chosen_batch_size==\"large\"):\n",
    "        if(chosen_network_structure==\"default\"):\n",
    "            command = f\"nnUNetv2_train 101 3d_fullresBS6 {chosen_fold}{trainer}\"\n",
    "        if(chosen_network_structure==\"ResEnc\"):\n",
    "            command = f\"nnUNetv2_train 101 3d_fullresBS4 {chosen_fold}{trainer} -p nnUNetResEncUNetMPlans\"\n",
    "\n",
    "print(command)\n",
    "start_time = time.time()\n",
    "!{command}\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time    \n",
    "elapsed_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
